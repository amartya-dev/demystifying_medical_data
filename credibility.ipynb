{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forward-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "credibility_scores = pd.read_excel(\"Data/webcredibility/web_credibility_1000_url_ratings.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "neutral-despite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Query</th>\n",
       "      <th>Result Rank</th>\n",
       "      <th>URL</th>\n",
       "      <th>Likert Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Celebrities</td>\n",
       "      <td>adam lambert</td>\n",
       "      <td>1</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Adam_Lambert</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Celebrities</td>\n",
       "      <td>adam lambert</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.adamofficial.com/us/intro</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Celebrities</td>\n",
       "      <td>adam lambert</td>\n",
       "      <td>3</td>\n",
       "      <td>http://www.adamofficial.com/us/home</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Celebrities</td>\n",
       "      <td>adam lambert</td>\n",
       "      <td>4</td>\n",
       "      <td>http://www.thehollywoodgossip.com/2010/06/new-...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Celebrities</td>\n",
       "      <td>adam lambert</td>\n",
       "      <td>5</td>\n",
       "      <td>http://www.americanidol.com/contestants/season...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Tea Party</td>\n",
       "      <td>36</td>\n",
       "      <td>http://stlouisteaparty.com/</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Tea Party</td>\n",
       "      <td>37</td>\n",
       "      <td>http://abcnews.go.com/Politics/tea-party-prote...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Tea Party</td>\n",
       "      <td>38</td>\n",
       "      <td>http://topics.politico.com/index.cfm/topic/Tea...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Tea Party</td>\n",
       "      <td>39</td>\n",
       "      <td>http://www.nationwidechicagoteaparty.com/</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Tea Party</td>\n",
       "      <td>40</td>\n",
       "      <td>http://party.kaboose.com/tea_party.html</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Topic         Query  Result Rank  \\\n",
       "0    Celebrities  adam lambert            1   \n",
       "1    Celebrities  adam lambert            2   \n",
       "2    Celebrities  adam lambert            3   \n",
       "3    Celebrities  adam lambert            4   \n",
       "4    Celebrities  adam lambert            5   \n",
       "..           ...           ...          ...   \n",
       "995     Politics     Tea Party           36   \n",
       "996     Politics     Tea Party           37   \n",
       "997     Politics     Tea Party           38   \n",
       "998     Politics     Tea Party           39   \n",
       "999     Politics     Tea Party           40   \n",
       "\n",
       "                                                   URL  Likert Rating  \n",
       "0            http://en.wikipedia.org/wiki/Adam_Lambert              5  \n",
       "1                 http://www.adamofficial.com/us/intro              4  \n",
       "2                  http://www.adamofficial.com/us/home              4  \n",
       "3    http://www.thehollywoodgossip.com/2010/06/new-...              3  \n",
       "4    http://www.americanidol.com/contestants/season...              4  \n",
       "..                                                 ...            ...  \n",
       "995                        http://stlouisteaparty.com/              3  \n",
       "996  http://abcnews.go.com/Politics/tea-party-prote...              4  \n",
       "997  http://topics.politico.com/index.cfm/topic/Tea...              3  \n",
       "998          http://www.nationwidechicagoteaparty.com/              3  \n",
       "999            http://party.kaboose.com/tea_party.html              4  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credibility_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-instrumentation",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Get the content from the url and get the following statistical features\n",
    "\n",
    "## Content Features\n",
    "- #exclamations Number of exclamation marks ”!” in the text\n",
    "- #commas Number of commas ”,” in the text\n",
    "- #dots Number of dots ”.” in the text\n",
    "- #questions Number of question marks ”?” in the text\n",
    "- #token count Text length as the number of words\n",
    "- ?polarity 0 if the page is negative, 1 if the page is positive\n",
    "- #positive Number of positive sentences\n",
    "- #negative Number of negative sentences\n",
    "- #subjective Number of subjective sentences\n",
    "- #objective Number of objective sentences\n",
    "- #spelling errors Number of spelling errors\n",
    "- @text complexity Text entropy\n",
    "- @informativeness Uniqueness of the page’s content relative to other pages\n",
    "- @smog Statistical measure of text readability\n",
    "- category Web page category, e.g., Entertainment, Business, etc.\n",
    "- #NN Number of nouns in the text\n",
    "- #VB Number of verbs in the text\n",
    "- #JJ Number of adjectives\n",
    "- #RB Number of adverbs\n",
    "- #DT Number of determiners\n",
    " \n",
    "## Appearance Features\n",
    "- #ad count Number of ads on the webpage\n",
    "- #ad max size The area in pixels of the biggest ad\n",
    "- #ad body ratio Ratio of the area of all ads to the area of the page\n",
    "- #css definitions Number of webpage CSS style definitions\n",
    "\n",
    "## Meta information\n",
    "- domain_type eg .com, .org etc.\n",
    "\n",
    "## Social popularity\n",
    "- #fb share Number of Facebook shares for a webpage URL\n",
    "- #fb like Number of Facebook likes for a webpage URL\n",
    "- #fb comment Number of Facebook comments for a webpage URL\n",
    "- #fb click Number of Facebook clicks for a webpage URL\n",
    "- #fb total Total Facebook shares, likes, comments and clicks\n",
    "- #tweets Number Tweets mentioning a webpage URL\n",
    "- #bitly clicks Number of Bitly short URL clicks for a webpage\n",
    "- #bitly referrers Number of web sites having Bitly short URL for a webpage\n",
    "- #delicious bookmarks Number of Delicious bookmarks for a webpage URL\n",
    "- @alexa_rank\n",
    "- #alexa_linksin Number of web site linkings estimated by Alexa\n",
    "- @page_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "jewish-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to extract features\n",
    "import math\n",
    "from newspaper import Article\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "\n",
    "def get_article_content(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return {\n",
    "        \"authors\": article.authors,\n",
    "        \"content\": article.text,\n",
    "    }\n",
    "\n",
    "def get_punctuations(content):\n",
    "    counts = Counter(content)\n",
    "    finders_list = \"!,.?\"\n",
    "    required_counts = {k:v for k, v in counts.items() if k in finders_list}\n",
    "    # get the required punctuations\n",
    "    punctuation_features = {\n",
    "        \"exclamations\": required_counts.get(\"!\", 0),\n",
    "        \"commas\": required_counts.get(\",\", 0),\n",
    "        \"dots\": required_counts.get(\".\", 0),\n",
    "        \"questions\": required_counts.get(\"?\", 0)\n",
    "    }\n",
    "    return punctuation_features\n",
    "\n",
    "def get_sentences(content):\n",
    "    return list(\n",
    "        filter(\n",
    "            lambda s: s != \"\",\n",
    "            list(\n",
    "                map(lambda s: s.strip(), content.split(\"\\n\"))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_word_related_stats(sentences):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    content = \". \".join(sentences)\n",
    "    doc = nlp(content)\n",
    "    num_words = len(doc)\n",
    "    c = Counter(([token.pos_ for token in doc]))\n",
    "    num_verbs = c.get('VERB')\n",
    "    num_nouns = c.get('NOUN')\n",
    "    num_adverbs = c.get('ADP')\n",
    "    num_determiners = c.get('DET')\n",
    "    all_words = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "    spelling_check_words = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop and not token.pos_ == \"PROPN\"]\n",
    "    all_words_counter = Counter(all_words)\n",
    "    entropy = 0\n",
    "    n = len(all_words)\n",
    "    for word_count in all_words_counter:\n",
    "        fi = all_words_counter.get(word_count)\n",
    "        entropy += fi * (math.log10(n) - math.log10(fi))\n",
    "    return {\n",
    "        'words': list(set(all_words)),\n",
    "        'spell_check': list(set(spelling_check_words)),\n",
    "        'num_words': num_words,\n",
    "        'num_verbs': num_verbs,\n",
    "        'num_adverbs': num_adverbs,\n",
    "        'num_determiners': num_determiners,\n",
    "        'text_entropy': entropy\n",
    "    }\n",
    "\n",
    "def get_spelling_errors(words):\n",
    "    checker = SpellChecker()\n",
    "    return checker.unknown(words)\n",
    "\n",
    "def get_sentiments_and_subjectivity(sentences):\n",
    "    dataset_name = 'imdb'\n",
    "    saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
    "    reloaded_model = tf.saved_model.load(saved_model_path)\n",
    "    sentiments = tf.sigmoid(reloaded_model(tf.constant(sentences)))\n",
    "    sentiments = list(map(lambda sentiment: round(sentiment), sentiments.numpy().flatten().tolist()))\n",
    "    subjectivity = [round(TextBlob(i).sentiment.subjectivity) for i in sentences]\n",
    "    return [sentiments, subjectivity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "designed-stress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fa11373bf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fa11373baf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fa134d358b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fa134d65d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "article = get_article_content(credibility_scores.iloc[0][\"URL\"])\n",
    "content = article.get('content')\n",
    "punctuations = get_punctuations(content)\n",
    "sentences = get_sentences(content)\n",
    "sentiments, subjectivity = get_sentiments_and_subjectivity(sentences)\n",
    "words_metrics = get_word_related_stats(sentences)\n",
    "spelling_errors = get_spelling_errors(words_metrics.get('words'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "compatible-facility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15330.82322081936"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_metrics.get(\"text_entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-carter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
